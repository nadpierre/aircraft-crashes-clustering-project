{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aircraft Crashes Data Collection And Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook collects and prepares the data for the analysis of all the aircraft accidents since 1970."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be scraped from the [BAAA Crash Archives](https://www.baaa-acro.com/crash-archives) and the [ASN Database](https://asn.flightsafety.org/database/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BAAA**\n",
    "\n",
    "`date` date and local time of the accident<br>\n",
    "`aircraft_type` aircraft make and model<br>\n",
    "`operator` operator of the aircraft<br>\n",
    "`registration` unique code to a single aircraft, required by international convention<br>\n",
    "`flight_phase` phase of the flight when the accident occured<br>\n",
    "`flight_type` type of flight (ex: military)<br>\n",
    "`survivors` indicates if there was survivors or not<br>\n",
    "`site` type of location where the accident happened (ex: mountains)<br>\n",
    "`departure` city where the departure was planned<br> \n",
    "`arrival` city where the arrival was planned<br> \n",
    "`msn` manufacturer's serial number of the aircraft<br>\n",
    "`yom` year of manufacture of the aircraft involved in the accident<br>\n",
    "`flight_number` flight number<br>\n",
    "`location` location of the accident<br>\n",
    "`country` country where the crash happened<br>\n",
    "`region` region of the world where the crash happened<br>\n",
    "`crew_on_board` number of crew members on board at the time of the accident<br>\n",
    "`crew_fatalities` number of crew members who died in the crash<br>\n",
    "`pax_on_board` number of passengers on board at the time of the accident<br> \n",
    "`pax_fatalities` number of passengers who died in the crash<br>                 \n",
    "`other_fatalities` other victims of the accident outside of the aircraft<br>\n",
    "`total_fatalities` total number of deaths<br>\n",
    "`captain_flying_hours` number of flying hours of the captain<br>\n",
    "`captain_flying_hours_on_type` number of hours the captain flew on the type of aircraft involved in the crash<br>\n",
    "`copilot_flying_hours` number of flying hours of the copilot<br>  \n",
    "`copilot_flying_hours_on_type` number of hours the copilot flew on the type of aircraft involved in the crash<br>  \n",
    "`aircraft_flying_hours` number of flying hours of the aircraft before the crash<br>\n",
    "`aircraft_flight_cycles` number of flights of the aircraft<br><br>\n",
    "\n",
    "\n",
    "**ASN**\n",
    "\n",
    "`date` date of the accident<br>\n",
    "`time` time of the accident<br>\n",
    "`type` make and model of the aircraft<br>\n",
    "`first_flight` year the aircraft was inaugurated<br>\n",
    "`engine` type and number of engines<br>\n",
    "`owner` operator of the aircraft<br>\n",
    "`registration` unique code to a single aircraft, required by international convention<br>\n",
    "`msn` manufacturer's serial number of the aircraft<br>\n",
    "`year_of_manufacture` year of manufacture of the aircraft involved in the accident<br>\n",
    "`total_airframe_hrs` number of flying hours of the aircraft before the crash<br>\n",
    "`cycles` number of flights of the aircraft<br>\n",
    "`engine_model` make and model of the aircraft engine<br>\n",
    "`fatalities` total number of fatalities<br>\n",
    "`occupants` number of crew members and passengers on board<br>\n",
    "`other_fatalities` other victims of the accident outside of the aircraft<br>\n",
    "`aircraft_damage` severity of the aircraft damage\n",
    "`category` type of accident<br>\n",
    "`location` location of the crash<br>\n",
    "`phase` phase of the flight when the accident occured<br>\n",
    "`nature` type of flight (ex: military)<br>\n",
    "`departure_airport` airport where the departure was planned<br>\n",
    "`destination_airport` airport when the arrival was planned<br>\n",
    "`investigating_agency` agency who made the accident deport<br>\n",
    "`confidence_rating` quality of the information (ex: missing information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from urllib.parse import unquote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_list_to_csv(data:list, csv_path:str) -> None:\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tif not os.path.isfile(csv_path):\n",
    "\t\tdf.to_csv(csv_path, index=False)\n",
    "\telse:\n",
    "\t\tdf.to_csv(csv_path, index=False, header=False, mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape total number of accidents\n",
    "root_url = 'https://www.baaa-acro.com'\n",
    "\n",
    "response = requests.get(root_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "accident_files = soup.find('div', {'class': 'total-accident-files'})\n",
    "nb_crashes = int(accident_files.text.replace(',', ''))\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape details of all accidents\n",
    "nb_rows_per_page = 20\n",
    "nb_pages = math.ceil(nb_crashes / nb_rows_per_page)\n",
    "csv_path = 'data/baaa_scraped_data.csv'\n",
    "\n",
    "for i in range(nb_pages):\n",
    "\tlisting_url = '{}/crash-archives?page={}'.format(root_url, i)\n",
    "\tresponse = requests.get(listing_url)\n",
    "\tsoup = BeautifulSoup(response.content, 'html.parser')\n",
    "\tanchors = soup.find_all('a', {'class': 'red-btn'})\n",
    "\n",
    "\tcrash_list = []\n",
    "\t\n",
    "\tfor j, a in enumerate(anchors):\n",
    "\t\tlink = a['href']\n",
    "\t\t#print('Page {}, link {}: {}{}'.format(i, j + 1, root_url, link))\n",
    "\t\tdetails_url = root_url + link\n",
    "\t\tresponse = requests.get(details_url)\n",
    "\t\tsoup = BeautifulSoup(response.content, 'html.parser')\n",
    "\t\tdetails = {}\n",
    "\t\t\n",
    "\t\tdetails_div = soup.find('div', {'class': 'crash-details'})\n",
    "\t\t\n",
    "\t\tdate_div = details_div.find('div', {'class': 'crash-date'})\n",
    "\t\tdetails['date'] = date_div.find('span').next_sibling.text.strip() if date_div else None\n",
    "\t\t\n",
    "\t\taircraft_div = details_div.find('div', {'class': 'crash-aircraft'})\n",
    "\t\tdetails['aircraft_type'] = aircraft_div.find('a').find('div').text if aircraft_div else None\n",
    "\t\t\n",
    "\t\toperator_div = details_div.find('div', {'class': 'crash-operator'})\n",
    "\n",
    "\t\tif operator_div:\n",
    "\t\t\tif (operator_div.find('img')): # Extract operator name from image link\n",
    "\t\t\t\tpattern = re.compile(r'(?<=target_id=).*(?= \\(\\d+\\))')\n",
    "\t\t\t\timg_link = unquote(operator_div.find('img').parent['href'])\n",
    "\t\t\t\tdetails['operator'] = pattern.search(img_link).group(0)\n",
    "\t\t\telse:\n",
    "\t\t\t\tdetails['operator'] = operator_div.find('a').find('div').text\n",
    "\t\telse:\n",
    "\t\t\tdetails['operator'] = None\n",
    "\n",
    "\t\treg_div = details_div.find('div', {'class': 'crash-registration'})\n",
    "\t\tdetails['registration'] = reg_div.find('div').text if reg_div else None\n",
    "\t\t\n",
    "\t\tflight_phase_div = details_div.find('div', {'class': 'crash-flight-phase'})\n",
    "\t\tdetails['flight_phase'] = flight_phase_div.find('a').find('div').text if flight_phase_div else None\n",
    "\t\t\n",
    "\t\tflight_type_div = details_div.find('div', {'class': 'crash-flight-type'})\n",
    "\t\tdetails['flight_type'] = flight_type_div.find('a').find('div').text if flight_type_div else None\n",
    "\t\t\n",
    "\t\tsurvivors_div = details_div.find('div', {'class': 'crash-survivors'})\n",
    "\t\tdetails['survivors'] = survivors_div.find('a').find('div').text if survivors_div else None\n",
    "\t\t\n",
    "\t\tsite_div = details_div.find('div', {'class': 'crash-site'})\n",
    "\t\tdetails['site'] = site_div.find('a').find('div').text if site_div else None\n",
    "\t\t\n",
    "\t\tschedule_div = details_div.find('div', {'class': 'crash-schedule'})\n",
    "\t\tdetails['schedule'] = schedule_div.find('div').text if schedule_div else None\n",
    "\t\t\n",
    "\t\tmsn_div = details_div.find('div', {'class': 'crash-construction-num'})\n",
    "\t\tdetails['msn'] = msn_div.find('div').text if msn_div else None\n",
    "\t\t\n",
    "\t\tyom_div = details_div.find('div', {'class': 'crash-yom'})\n",
    "\t\tdetails['yom'] = yom_div.find('div').text if yom_div else None\n",
    "\n",
    "\t\tflight_number = details_div.find('div', {'class': 'crash-flight-number'})\n",
    "\t\tdetails['flight_number'] = flight_number.find('div').text if flight_number else None\n",
    "\t\t\n",
    "\t\tlocation_div = details_div.find('div', {'class': 'crash-location'})\n",
    "\t\tif location_div:\n",
    "\t\t\tlocation_details = location_div.select('a')\n",
    "\t\t\tdetails['location'] = ', '.join(item.text.strip() for item in location_details) if location_details else None\n",
    "\t\telse:\n",
    "\t\t\tdetails['location'] = None\n",
    "\t\t\n",
    "\t\tcountry_div = details_div.find('div', {'class': 'crash-country'})\n",
    "\t\tdetails['country'] = country_div.find('a').find('div').text if country_div else None\n",
    "\t\t\n",
    "\t\tregion_div = details_div.find('div', {'class': 'crash-region'})\n",
    "\t\tdetails['region'] = region_div.find('a').find('div').text if region_div else None\n",
    "\t\t\n",
    "\t\tcrew_on_board_div = details_div.find('div', {'class': 'crash-crew-on-board'})\n",
    "\t\tdetails['crew_on_board'] = crew_on_board_div.find('div').text if crew_on_board_div else None\n",
    "\t\t\n",
    "\t\tcrew_fatalities_div = details_div.find('div', {'class': 'crash-crew-fatalities'})\n",
    "\t\tdetails['crew_fatalities'] = crew_fatalities_div.find('div').text if crew_fatalities_div else None\n",
    "\t\t\n",
    "\t\tpax_on_board_div = details_div.find('div', {'class': 'crash-pax-on-board'})\n",
    "\t\tdetails['pax_on_board'] = pax_on_board_div.find('div').text if pax_on_board_div else None\n",
    "\t\t\n",
    "\t\tpax_fatalities_div = details_div.find('div', {'class': 'crash-pax-fatalities'})\n",
    "\t\tdetails['pax_fatalities'] = pax_fatalities_div.find('div').text if pax_fatalities_div else None\n",
    "\t\t\n",
    "\t\tothers_div = details_div.find('div', {'class': 'crash-other-fatalities'})\n",
    "\t\tdetails['other_fatalities'] = others_div.find('div').text if others_div else None\n",
    "\t\t\n",
    "\t\ttotal_fatalities_div = details_div.find('div', {'class': 'crash-total-fatalities'})\n",
    "\t\tdetails['total_fatalities'] = total_fatalities_div.find('div').text if total_fatalities_div else None\n",
    "\n",
    "\t\tcaptain_hours_div = details_div.find('div', {'class': 'captain-total-flying-hours'})\n",
    "\t\tdetails['captain_flying_hours'] = captain_hours_div.find('div').text if captain_hours_div else None\n",
    "\n",
    "\t\tcaptain_hours_type_div = details_div.find('div', {'class': 'captain-total-hours-type'})\n",
    "\t\tdetails['captain_flying_hours_on_type'] = captain_hours_type_div.find('div').text if captain_hours_type_div else None\n",
    "\n",
    "\t\tcopilot_hours_div = details_div.find('div', {'class': 'copilot-total-flying-hours'})\n",
    "\t\tdetails['copilot_flying_hours'] = copilot_hours_div.find('div').text if copilot_hours_div else None\n",
    "\n",
    "\t\tcopilot_hours_type_div = details_div.find('div', {'class': 'copilot-total-hours-type'})\n",
    "\t\tdetails['copilot_flying_hours_on_type'] = copilot_hours_type_div.find('div').text if copilot_hours_type_div else None\n",
    "\n",
    "\t\taircraft_hours_div = details_div.find('div', {'class': 'crash-aircraft-flight-hours'})\n",
    "\t\tdetails['aircraft_flying_hours'] = aircraft_hours_div.find('div').text if aircraft_hours_div else None\n",
    "\n",
    "\t\taircraft_cycles_div = details_div.find('div', {'class': 'crash-aircraft-flight-cycles'})\n",
    "\t\tdetails['aircraft_flight_cycles'] = aircraft_cycles_div.find('div').text if aircraft_cycles_div else None\n",
    "\t\t\n",
    "\t\tcrash_list.append(details)\n",
    "\t\n",
    "\texport_list_to_csv(crash_list, csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape accident causes\n",
    "csv_path = 'data/baaa_crash_reasons.csv'\n",
    "\n",
    "reasons = {\n",
    "  'Human factor': 12990,\n",
    "  'Other causes': 12992,\n",
    "  'Technical failure': 12988,\n",
    "  'Terrorism act, hijacking, sabotage, any kind of hostile action': 12991,\n",
    "  'Unknown': 12993,\n",
    "  'Weather': 12989\n",
    "}\n",
    "\n",
    "for reason, target_id in reasons.items():\n",
    "\turl = 'https://www.baaa-acro.com/crash-archives?field_crash_cause_target_id={}'.format(target_id)\n",
    "\tresponse = requests.get(url)\n",
    "\tsoup = BeautifulSoup(response.content, 'html.parser')\n",
    "\tpattern = re.compile(r'\\d+$')\n",
    "\ttotal_items_txt = soup.find('div', {'class': 'view-header'}).find('span').text\n",
    "\ttotal_items = int(pattern.search(total_items_txt).group(0))\n",
    "\tnb_items_per_page = 20\n",
    "\tnb_pages = math.ceil(total_items / nb_items_per_page)\n",
    "\t\n",
    "\tfor i in range(nb_pages):\n",
    "\t\tpage_url = url + '&page={}'.format(i)\n",
    "\t\tpage_response = requests.get(page_url)\n",
    "\t\tpage_soup = BeautifulSoup(page_response.content, 'html.parser')\n",
    "\t\ttable = page_soup.find('table')\n",
    "\t\trows = table.find_all('tr')\n",
    "\n",
    "\t\tcrash_list = []\n",
    "\t\tfor row in rows[1:]: # skip table header\n",
    "\t\t\tcreated = row.find('td', {'class': 'views-field-created'}).find('time').text\n",
    "\t\t\tregistration_div = row.find('div', {'class': 'registration-field'})\n",
    "\t\t\tcrash_list.append({\n",
    "\t\t\t\t'date': created,\n",
    "\t\t\t\t'registration': registration_div.text if registration_div else None,\n",
    "\t\t\t\t'cause': reason\n",
    "\t\t\t})\n",
    "\t\texport_list_to_csv(crash_list, csv_path)\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'data/asn_scraped_data.csv'\n",
    "root_url = 'https://asn.flightsafety.org'\n",
    "\n",
    "# Add headers to avoid 403 unauthorized error\n",
    "headers = {\n",
    "  'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "database = '/database'\n",
    "database_url = root_url + database\n",
    "\n",
    "#for year in range(1919, 2026):\n",
    "for year in range(1973, 2026):\n",
    "\tyear_url = '{}{}/year/{}/1'.format(root_url, database, year)\n",
    "\tresponse = requests.get(year_url, headers=headers)\n",
    "\tsoup = BeautifulSoup(response.content, 'html.parser')\n",
    "\tnb_occurences_txt = soup.find('div', {'class': 'innertube'}).find('span').text\n",
    "\tpattern = re.compile(r'\\d+(?= occurrences)')\n",
    "\tnb_occurences = int(pattern.search(nb_occurences_txt).group(0))\n",
    "\tmax_items_per_page = 100\n",
    "\tnb_pages = math.ceil(nb_occurences / max_items_per_page)\n",
    "\n",
    "\t#for page in range(1, nb_pages + 1):\n",
    "\tfor page in range(1, nb_pages + 1):\n",
    "\t\tpage_url = '{}{}/year/{}/{}'.format(root_url, database, year, page)\n",
    "\t\tresponse = requests.get(page_url, headers=headers)\n",
    "\t\tsoup = BeautifulSoup(response.content, 'html.parser')\n",
    "\t\ttable = soup.find('table', {'class': 'hp'})\n",
    "\t\tanchors = table.find_all('a')\n",
    "\t\tlinks = [a['href'] for a in anchors]\n",
    "\t\t\n",
    "\t\tcrash_list = []\n",
    "\t\tfor i, link in enumerate(links):\n",
    "\t\t\tdetails_url = root_url + link\n",
    "\t\t\tprint('Year {}, page {}, item {}, link: {}'.format(year, page, i + 1, details_url))\n",
    "\t\t\tresponse = requests.get(details_url, headers=headers)\n",
    "\t\t\tsoup = BeautifulSoup(response.content, 'html.parser')\n",
    "\t\t\ttable = soup.find('table')\n",
    "\t\t\tdetails = {}\n",
    "\n",
    "\t\t\tdate_label = table.find('td', string='Date:')\n",
    "\t\t\tdetails['date'] = date_label.next_sibling.text\n",
    "\n",
    "\t\t\ttime_label = table.find('td', string='Time:')\n",
    "\t\t\tdetails['time'] = time_label.next_sibling.text\n",
    "\n",
    "\t\t\ttype_label = table.find('td', string='Type:')\n",
    "\t\t\tanchor = type_label.next_sibling.find('a')\n",
    "\n",
    "\t\t\tif anchor: # Get more details about aircraft if link exists\n",
    "\t\t\t\tdetails['type'] = anchor.text\n",
    "\t\t\t\thref = anchor['href']\n",
    "\t\t\t\ttype_url = root_url + href\n",
    "\t\t\t\ttype_response = requests.get(type_url, headers=headers)\n",
    "\t\t\t\ttype_soup = BeautifulSoup(type_response.content, 'html.parser')\n",
    "\t\t\t\ttype_table = type_soup.find('table')\n",
    "\t\t\t\ttype_details = list(type_table.find('td', {'valign': 'top'}).stripped_strings)\n",
    "\t\t\t\tdetails['type_details'] = ', '.join(type_details)\n",
    "\t\t\telse:\n",
    "\t\t\t\tdetails['type'] = type_label.next_sibling.text\n",
    "\t\t\t\tdetails['type_details'] = None\n",
    "\n",
    "\t\t\towner_label = table.find('td', string='Owner/operator:')\n",
    "\t\t\tdetails['owner'] = owner_label.next_sibling.text\n",
    "\n",
    "\t\t\treg_label = table.find('td', string='Registration:')\n",
    "\t\t\tdetails['registration'] = reg_label.next_sibling.text\n",
    "\n",
    "\t\t\tmsn_label = table.find('td', string='MSN:')\n",
    "\t\t\tdetails['msn'] = msn_label.next_sibling.text\n",
    "\n",
    "\t\t\tyom_label = table.find('td', string='Year of manufacture:')\n",
    "\t\t\tdetails['year_of_manufacture'] = yom_label.next_sibling.text if yom_label else None\n",
    "\n",
    "\t\t\tair_hours_label = table.find('td', string='Total airframe hrs:')\n",
    "\t\t\tdetails['total_airframe_hrs'] = air_hours_label.next_sibling.text if air_hours_label else None\n",
    "\n",
    "\t\t\tcycles_label = table.find('td', string='Cycles:')\n",
    "\t\t\tdetails['cycles'] = cycles_label.next_sibling.text if cycles_label else None\n",
    "\n",
    "\t\t\tengine_label = table.find('td', string='Engine model:')\n",
    "\t\t\tdetails['engine_model'] = engine_label.next_sibling.text if engine_label else None\n",
    "\n",
    "\t\t\tfatal_label = table.find('td', string='Fatalities:')\n",
    "\t\t\tdetails['fatalities'] = fatal_label.next_sibling.text\n",
    "\n",
    "\t\t\tother_label = table.find('td', string='Other fatalities:')\n",
    "\t\t\tdetails['other_fatalities'] = other_label.next_sibling.text\n",
    "\n",
    "\t\t\tdamage_label = table.find('td', string='Aircraft damage:')\n",
    "\t\t\tdetails['aircraft_damage'] = damage_label.next_sibling.text\n",
    "\n",
    "\t\t\tcat_label = table.find('td', string='Category:')\n",
    "\t\t\tdetails['category'] = cat_label.next_sibling.text if cat_label else None\n",
    "\n",
    "\t\t\tloc_label = table.find('td', string='Location:')\n",
    "\t\t\tdetails['location'] = ' '.join(loc_label.next_sibling.stripped_strings)\n",
    "\n",
    "\t\t\tphase_label = table.find('td', string='Phase:')\n",
    "\t\t\tdetails['phase'] = phase_label.next_sibling.text\n",
    "\n",
    "\t\t\tnature_label = table.find('td', string='Nature:')\n",
    "\t\t\tdetails['nature'] = nature_label.next_sibling.text\n",
    "\n",
    "\t\t\tdep_label = table.find('td', string='Departure airport:')\n",
    "\t\t\tdetails['departure_airport'] = dep_label.next_sibling.text\n",
    "\n",
    "\t\t\tdes_label = table.find('td', string='Destination airport:')\n",
    "\t\t\tdetails['destination_airport'] = des_label.next_sibling.text\n",
    "\n",
    "\t\t\tinv_label = table.find('td', string=re.compile('Investigating'))\n",
    "\t\t\tdetails['investigating_agency'] = inv_label.next_sibling.text if inv_label else None\n",
    "\n",
    "\t\t\tconf_label = table.find('td', string='Confidence Rating:')\n",
    "\t\t\tdetails['confidence_rating'] = ''.join(conf_label.next_sibling.stripped_strings) if conf_label else None\n",
    "\n",
    "\t\t\tcrash_list.append(details)\n",
    "\t\t\n",
    "\t\texport_list_to_csv(crash_list, csv_path)\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from geopy.geocoders import Nominatim\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crashes\n",
    "baaa_df = pd.read_csv('data/baaa_scraped_data.csv')\n",
    "baaa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Causes\n",
    "baaa_causes_df = pd.read_csv('data/baaa_crash_reasons.csv', parse_dates=['date'], date_format='%b %d, %Y')\n",
    "baaa_causes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baaa_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baaa_causes_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baaa_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baaa_causes_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "baaa_df[baaa_df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baaa_causes_df[baaa_causes_df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asn_df = pd.read_csv('data/asn_scraped_data.csv')\n",
    "asn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asn_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asn_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "asn_df[asn_df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "baaa_df = baaa_df.drop_duplicates()\n",
    "baaa_causes_df = baaa_causes_df.drop_duplicates()\n",
    "asn_df = asn_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip whitespaces\n",
    "def remove_whitespaces(df):\n",
    "\tfor column in df.columns:\n",
    "\t\tif df[column].dtype == 'object':\n",
    "\t\t\tdf[column] = df[column].str.strip()\n",
    "\treturn df\n",
    "\n",
    "baaa_df = remove_whitespaces(baaa_df)\n",
    "baaa_causes_df = remove_whitespaces(baaa_causes_df)\n",
    "asn_df = remove_whitespaces(asn_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge dataframes on date and registration number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it's not very likely, the same aircraft can be involved in multiple accidents. Combining the registration number and the date ensures the unicity of the rows.\n",
    "\n",
    "The main (left) dataset will be the one from BAAA as it's the most reliable and the second (right) one will be ASN dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert BAAA date to datetime\n",
    "baaa_df['date'] = pd.to_datetime(baaa_df['date'], format='%b %d, %Y at %H%M LT', errors='coerce') \\\n",
    "\t\t\t\t.fillna(pd.to_datetime(baaa_df['date'], format='%b %d, %Y', errors='coerce'))\n",
    "assert baaa_df['date'].isna().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ASN date to datetime\n",
    "asn_df['date'] = pd.to_datetime(asn_df['date'], format='%A %d %B %Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date string column\n",
    "baaa_df['date_str'] = baaa_df['date'].dt.strftime('%Y-%m-%d')\n",
    "baaa_causes_df['date_str'] = baaa_causes_df['date'].dt.strftime('%Y-%m-%d')\n",
    "asn_df['date_str'] = asn_df['date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge three dataframes\n",
    "df = pd.merge(left=baaa_df, right=baaa_causes_df, how='left', on=['registration', 'date_str'])\n",
    "df = pd.merge(left=df, right=asn_df, how='left', on=['registration', 'date_str'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove time from datetime and drop other date and timecolumns\n",
    "df['date'] = pd.to_datetime(df['date_str'])\n",
    "df = df.drop(['date_x', 'date_y', 'time', 'date_str'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep data from 1970 to now\n",
    "df = df[df['date'].dt.year >= 1970]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge location (BAAA, then ASN, then country)\n",
    "df['location_y'] = df['location_y'].str.replace(' - ', ', ')\n",
    "df['location'] = df['location_x'].fillna(df['location_y']).fillna(df['country'])\n",
    "df = df.drop(['location_x', 'location_y'], axis=1)\n",
    "assert df['location'].isnull().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coordinates from geocoder\n",
    "geolocator = Nominatim(user_agent='aircraft_crashes_analysis')\n",
    "geocoder = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n",
    "\n",
    "def get_coord(row, column:str='location') -> tuple:\n",
    "\tresult = (np.nan, np.nan)\n",
    "\n",
    "\tlocation = geocoder(row[column], language='en', exactly_one=True)\n",
    "\n",
    "\tif (location):\n",
    "\t\tprint('Coordinates: ({}, {})'.format(location.latitude, location.longitude))\n",
    "\t\tresult = (location.latitude, location.longitude)\n",
    "\t\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create columns with coordinates\n",
    "coordinates = df.apply(get_coord, axis=1, result_type='expand')\n",
    "coordinates.columns = ['latitude', 'longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data even if it's not completely clean\n",
    "# Because it takes a long time to get the coordinates\n",
    "df = df.join(coordinates)\n",
    "df.to_csv('data/merged_data_with_coordinates.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue data cleaning with added coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aircraft_type</th>\n",
       "      <th>operator</th>\n",
       "      <th>registration</th>\n",
       "      <th>flight_phase</th>\n",
       "      <th>flight_type</th>\n",
       "      <th>survivors</th>\n",
       "      <th>site</th>\n",
       "      <th>schedule</th>\n",
       "      <th>msn_x</th>\n",
       "      <th>yom</th>\n",
       "      <th>...</th>\n",
       "      <th>category</th>\n",
       "      <th>phase</th>\n",
       "      <th>nature</th>\n",
       "      <th>departure_airport</th>\n",
       "      <th>destination_airport</th>\n",
       "      <th>investigating_agency</th>\n",
       "      <th>confidence_rating</th>\n",
       "      <th>location</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAe Jetstream 31</td>\n",
       "      <td>Línea Aérea Nacional de Honduras - LANHSA</td>\n",
       "      <td>HR-AYW</td>\n",
       "      <td>Takeoff (climb)</td>\n",
       "      <td>Scheduled Revenue Flight</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lake, Sea, Ocean, River</td>\n",
       "      <td>Roatán – La Ceiba</td>\n",
       "      <td>863</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Accident</td>\n",
       "      <td>Initial climb</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>Roatán-Juan Manuel Gálvez International Airpor...</td>\n",
       "      <td>La Ceiba-Goloson International Airport (LCE/MHLC)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Information is only available from news, socia...</td>\n",
       "      <td>Roatán Islas de la Bahía</td>\n",
       "      <td>16.349021</td>\n",
       "      <td>-86.497751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cessna 525 CitationJet CJ2</td>\n",
       "      <td>LBL 525 CZ LLC</td>\n",
       "      <td>N525CZ</td>\n",
       "      <td>Takeoff (climb)</td>\n",
       "      <td>Private</td>\n",
       "      <td>No</td>\n",
       "      <td>Plain, Valley</td>\n",
       "      <td>Mesquite - Addison</td>\n",
       "      <td>525A-0380</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Accident</td>\n",
       "      <td>Initial climb</td>\n",
       "      <td>Ferry/positioning</td>\n",
       "      <td>Mesquite Metro Airport, TX (KHQZ)</td>\n",
       "      <td>Dallas-Addison Airport, TX (ADS/KADS)</td>\n",
       "      <td>NTSB</td>\n",
       "      <td>Information is only available from news, socia...</td>\n",
       "      <td>Mesquite Metro, Texas</td>\n",
       "      <td>32.749899</td>\n",
       "      <td>-96.531150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Antonov AN-32</td>\n",
       "      <td>Indian Air Force - Bharatiya Vayu Sena</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Landing (descent or approach)</td>\n",
       "      <td>Military</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Airport (less than 10 km from airport)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bagdogra, West Bengal</td>\n",
       "      <td>26.698109</td>\n",
       "      <td>88.324546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAe Jetstream 31</td>\n",
       "      <td>SAETA Perú (Servicios Aéreos Tarapota)</td>\n",
       "      <td>OB-2178</td>\n",
       "      <td>Landing (descent or approach)</td>\n",
       "      <td>Scheduled Revenue Flight</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Airport (less than 10 km from airport)</td>\n",
       "      <td>Iquitos - Güeppí</td>\n",
       "      <td>861</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Accident</td>\n",
       "      <td>Landing</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>Iquitos-Coronel FAP Francisco Secada Vignetta ...</td>\n",
       "      <td>Güeppi Airport (SPGP)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Information is only available from news, socia...</td>\n",
       "      <td>Güeppí, Loreto</td>\n",
       "      <td>-0.117674</td>\n",
       "      <td>-75.251080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antonov AN-26</td>\n",
       "      <td>Sudanese Air Force - Al Quwwat al-Jawwiya As-S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Takeoff (climb)</td>\n",
       "      <td>Military</td>\n",
       "      <td>No</td>\n",
       "      <td>City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wadi Seidna AFB, Khartoum (الخرطوم)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                aircraft_type  \\\n",
       "0            BAe Jetstream 31   \n",
       "1  Cessna 525 CitationJet CJ2   \n",
       "2               Antonov AN-32   \n",
       "3            BAe Jetstream 31   \n",
       "4               Antonov AN-26   \n",
       "\n",
       "                                            operator registration  \\\n",
       "0          Línea Aérea Nacional de Honduras - LANHSA       HR-AYW   \n",
       "1                                     LBL 525 CZ LLC       N525CZ   \n",
       "2             Indian Air Force - Bharatiya Vayu Sena          NaN   \n",
       "3             SAETA Perú (Servicios Aéreos Tarapota)      OB-2178   \n",
       "4  Sudanese Air Force - Al Quwwat al-Jawwiya As-S...          NaN   \n",
       "\n",
       "                    flight_phase               flight_type survivors  \\\n",
       "0                Takeoff (climb)  Scheduled Revenue Flight       Yes   \n",
       "1                Takeoff (climb)                   Private        No   \n",
       "2  Landing (descent or approach)                  Military       Yes   \n",
       "3  Landing (descent or approach)  Scheduled Revenue Flight       Yes   \n",
       "4                Takeoff (climb)                  Military        No   \n",
       "\n",
       "                                     site            schedule      msn_x  \\\n",
       "0                 Lake, Sea, Ocean, River   Roatán – La Ceiba        863   \n",
       "1                           Plain, Valley  Mesquite - Addison  525A-0380   \n",
       "2  Airport (less than 10 km from airport)                 NaN        NaN   \n",
       "3  Airport (less than 10 km from airport)    Iquitos - Güeppí        861   \n",
       "4                                    City                 NaN        NaN   \n",
       "\n",
       "      yom  ...  category          phase             nature  \\\n",
       "0  1990.0  ...  Accident  Initial climb          Passenger   \n",
       "1  2007.0  ...  Accident  Initial climb  Ferry/positioning   \n",
       "2     NaN  ...       NaN            NaN                NaN   \n",
       "3  1989.0  ...  Accident        Landing          Passenger   \n",
       "4     NaN  ...       NaN            NaN                NaN   \n",
       "\n",
       "                                   departure_airport  \\\n",
       "0  Roatán-Juan Manuel Gálvez International Airpor...   \n",
       "1                  Mesquite Metro Airport, TX (KHQZ)   \n",
       "2                                                NaN   \n",
       "3  Iquitos-Coronel FAP Francisco Secada Vignetta ...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                 destination_airport  investigating_agency  \\\n",
       "0  La Ceiba-Goloson International Airport (LCE/MHLC)                   NaN   \n",
       "1              Dallas-Addison Airport, TX (ADS/KADS)                  NTSB   \n",
       "2                                                NaN                   NaN   \n",
       "3                              Güeppi Airport (SPGP)                   NaN   \n",
       "4                                                NaN                   NaN   \n",
       "\n",
       "                                   confidence_rating  \\\n",
       "0  Information is only available from news, socia...   \n",
       "1  Information is only available from news, socia...   \n",
       "2                                                NaN   \n",
       "3  Information is only available from news, socia...   \n",
       "4                                                NaN   \n",
       "\n",
       "                              location   latitude  longitude  \n",
       "0             Roatán Islas de la Bahía  16.349021 -86.497751  \n",
       "1                Mesquite Metro, Texas  32.749899 -96.531150  \n",
       "2                Bagdogra, West Bengal  26.698109  88.324546  \n",
       "3                       Güeppí, Loreto  -0.117674 -75.251080  \n",
       "4  Wadi Seidna AFB, Khartoum (الخرطوم)        NaN        NaN  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load merged data\n",
    "df = pd.read_csv('data/merged_data_with_coordinates.csv', parse_dates=['date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split some columns into multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split schedule into 2 columns\n",
    "schedule = df['schedule'].str.split(' - ', expand=True)\n",
    "df['departure'] = schedule[0]\n",
    "df['arrival'] = schedule[1]\n",
    "df = df.drop('schedule', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split type details into 2 columns\n",
    "df['type_details'] = df['type_details'].str.extract(r'(\\bFirst flight: \\d{4}, .*)$', expand=False)\n",
    "details = df['type_details'].str.split(', ', expand=True)\n",
    "df['first_flight'] = details[0].str.extract(r'(\\d{4})', expand=False)\n",
    "df['engine'] = details[1]\n",
    "df = df.drop('type_details', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split fatalities from ASN\n",
    "fatalities = df['fatalities'].str.split(' / ', expand=True)\n",
    "df['fatalities'] = fatalities[0].str.extract(r'(\\d+)')\n",
    "df['occupants'] = fatalities[1].str.extract(r'(\\d+)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge common columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['operator'] = df['operator'].fillna(df['owner'])\n",
    "df = df.drop('owner', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'] = df['aircraft_type'].fillna(df['type'])\n",
    "df = df.drop('aircraft_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yom'] = df['yom'].fillna(df['year_of_manufacture'])\n",
    "df = df.drop('year_of_manufacture', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['aircraft_flying_hours'] = df['aircraft_flying_hours'].fillna(df['total_airframe_hrs'])\n",
    "df = df.drop('total_airframe_hrs', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['aircraft_flight_cycles'] = df['aircraft_flight_cycles'].fillna(df['cycles'])\n",
    "df = df.drop('cycles', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['msn'] = df['msn_x'].fillna(df['msn_y'])\n",
    "df = df.drop(['msn_x', 'msn_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['flight_phase'] = df['flight_phase'].fillna(df['phase'])\n",
    "df = df.drop('phase', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['flight_type'] = df['flight_type'].fillna(df['nature'])\n",
    "df = df.drop('nature', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['departure'] = df['departure_airport'].fillna(df['departure'])\n",
    "df = df.drop('departure_airport', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['arrival'] = df['destination_airport'].fillna(df['arrival'])\n",
    "df = df.drop('destination_airport', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_board = df['crew_on_board'] + df['pax_on_board']\n",
    "df['occupants'] = on_board.fillna(df['occupants'])\n",
    "df = df.drop(['crew_on_board', 'pax_on_board'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fatalities'] = df['total_fatalities'].fillna(df['fatalities'])\n",
    "df = df.drop(['crew_fatalities', 'pax_fatalities', 'total_fatalities'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['other_fatalities'] = df['other_fatalities_x'].fillna(df['other_fatalities_y'])\n",
    "df = df.drop(['other_fatalities_x', 'other_fatalities_y'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inpute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_columns():\n",
    "\tis_null = df.isna().sum()\n",
    "\tcolumns = is_null[is_null > 0].index\n",
    "\treturn df[columns].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13647 entries, 0 to 13646\n",
      "Data columns (total 28 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   registration                  13383 non-null  object \n",
      " 1   flight_phase                  13531 non-null  object \n",
      " 2   flight_type                   13634 non-null  object \n",
      " 3   survivors                     13299 non-null  object \n",
      " 4   site                          13526 non-null  object \n",
      " 5   yom                           13000 non-null  float64\n",
      " 6   flight_number                 2093 non-null   object \n",
      " 7   captain_flying_hours          5665 non-null   float64\n",
      " 8   captain_flying_hours_on_type  4777 non-null   float64\n",
      " 9   copilot_flying_hours          1616 non-null   float64\n",
      " 10  copilot_flying_hours_on_type  1437 non-null   float64\n",
      " 11  aircraft_flying_hours         4656 non-null   object \n",
      " 12  aircraft_flight_cycles        1395 non-null   object \n",
      " 13  cause                         13615 non-null  object \n",
      " 14  engine_model                  4837 non-null   object \n",
      " 15  aircraft_damage               7437 non-null   object \n",
      " 16  category                      7372 non-null   object \n",
      " 17  investigating_agency          2499 non-null   object \n",
      " 18  confidence_rating             4307 non-null   object \n",
      " 19  latitude                      10203 non-null  float64\n",
      " 20  longitude                     10203 non-null  float64\n",
      " 21  departure                     11089 non-null  object \n",
      " 22  arrival                       9833 non-null   object \n",
      " 23  first_flight                  6946 non-null   object \n",
      " 24  engine                        6946 non-null   object \n",
      " 25  occupants                     13634 non-null  object \n",
      " 26  msn                           13094 non-null  object \n",
      " 27  other_fatalities              13641 non-null  float64\n",
      "dtypes: float64(8), object(20)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "get_null_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['operator', 'registration', 'flight_phase', 'flight_type', 'site',\n",
       "       'flight_number', 'country', 'region', 'cause', 'type', 'engine_model',\n",
       "       'aircraft_damage', 'category', 'investigating_agency',\n",
       "       'confidence_rating', 'location', 'departure', 'arrival', 'engine',\n",
       "       'msn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get string columns\n",
    "string_columns = df.drop([\n",
    "  'survivors',\n",
    "  'aircraft_flying_hours',\n",
    "  'aircraft_flight_cycles',\n",
    "  'occupants',\n",
    "  'first_flight'], axis=1).select_dtypes(include='object').columns\n",
    "string_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing string columns with Unknown\n",
    "for column in string_columns:\n",
    "\tdf[column] = df[column].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13647 entries, 0 to 13646\n",
      "Data columns (total 13 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   survivors                     13299 non-null  object \n",
      " 1   yom                           13000 non-null  float64\n",
      " 2   captain_flying_hours          5665 non-null   float64\n",
      " 3   captain_flying_hours_on_type  4777 non-null   float64\n",
      " 4   copilot_flying_hours          1616 non-null   float64\n",
      " 5   copilot_flying_hours_on_type  1437 non-null   float64\n",
      " 6   aircraft_flying_hours         4656 non-null   object \n",
      " 7   aircraft_flight_cycles        1395 non-null   object \n",
      " 8   latitude                      10203 non-null  float64\n",
      " 9   longitude                     10203 non-null  float64\n",
      " 10  first_flight                  6946 non-null   object \n",
      " 11  occupants                     13634 non-null  object \n",
      " 12  other_fatalities              13641 non-null  float64\n",
      "dtypes: float64(8), object(5)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "get_null_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_null_mask = df['occupants'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values by 0 to be able to convert it to string\n",
    "df['occupants'] = df['occupants'].fillna(0)\n",
    "df['occupants'] = df['occupants'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing occupants by average per type of aircraft\n",
    "df.loc[is_null_mask, 'occupants'] = df[is_null_mask].groupby('type')['occupants'].transform('mean')\n",
    "assert df['occupants'].isna().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure fatalities are not greater than occupants\n",
    "df.loc[df['fatalities'] > df['occupants'], 'fatalities'] = df['occupants']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing survivors and convert to boolean\n",
    "df['survivors'] = np.where(df['occupants'] > df['fatalities'], True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13647 entries, 0 to 13646\n",
      "Data columns (total 11 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   yom                           13000 non-null  float64\n",
      " 1   captain_flying_hours          5665 non-null   float64\n",
      " 2   captain_flying_hours_on_type  4777 non-null   float64\n",
      " 3   copilot_flying_hours          1616 non-null   float64\n",
      " 4   copilot_flying_hours_on_type  1437 non-null   float64\n",
      " 5   aircraft_flying_hours         4656 non-null   object \n",
      " 6   aircraft_flight_cycles        1395 non-null   object \n",
      " 7   latitude                      10203 non-null  float64\n",
      " 8   longitude                     10203 non-null  float64\n",
      " 9   first_flight                  6946 non-null   object \n",
      " 10  other_fatalities              13641 non-null  float64\n",
      "dtypes: float64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "get_null_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input missing yom with year - average age\n",
    "df['aircraft_age'] = df['date'].dt.year - df['yom']\n",
    "df['aircraft_age'] = df['aircraft_age'].fillna(int(df['aircraft_age'].mean()))\n",
    "df['yom'] = df['yom'].fillna(df['date'].dt.year - df['aircraft_age'])\n",
    "assert df['yom'].isna().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Approach' 'En route' 'Flight' 'Landing' 'Landing (descent or approach)'\n",
      " 'Parking' 'Standing' 'Take off' 'Takeoff (climb)' 'Taxiing' 'Unknown']\n",
      "['Flight' 'Landing (descent or approach)' 'Parking' 'Takeoff (climb)'\n",
      " 'Taxiing' 'Unknown']\n"
     ]
    }
   ],
   "source": [
    "# Regroup flight phases\n",
    "print(df['flight_phase'].sort_values().unique())\n",
    "df['flight_phase'] = np.where(df['flight_phase'].isin(['Take off', 'Initial climb']), 'Takeoff (climb)', df['flight_phase'])\n",
    "df['flight_phase'] = np.where(df['flight_phase'] == 'En route', 'Flight', df['flight_phase'])\n",
    "df['flight_phase'] = np.where(df['flight_phase'].isin(['Landing', 'Approach']), 'Landing (descent or approach)', df['flight_phase'])\n",
    "df['flight_phase'] = np.where(df['flight_phase'] == 'Taxi', 'Taxiing', df['flight_phase'])\n",
    "df['flight_phase'] = np.where(df['flight_phase'] == 'Standing', 'Parking', df['flight_phase'])\n",
    "print(df['flight_phase'].sort_values().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_coordinates = (df['latitude'].isna()) | (df['longitude'].isna())\n",
    "close_to_airport = df['site'].str.contains('Airport')\n",
    "take_off = df['flight_phase'].str.contains('Takeoff')\n",
    "landing = df['flight_phase'].str.contains('Landing')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Fill missing latitude and longitude with departure or arrival coordinates\n",
    "# If crash happened close to an airport\n",
    "coordinates\t= df[null_coordinates & close_to_airport & take_off].apply(get_coord, column='departure', axis=1, result_type='expand')\n",
    "df.loc[null_coordinates & close_to_airport & take_off, 'latitude'] = coordinates[0]\n",
    "df.loc[null_coordinates & close_to_airport & take_off, 'longitude'] = coordinates[1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Save data again because of the geocoding\n",
    "df.to_csv('data/imputed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "coordinates\t= df[null_coordinates & close_to_airport & landing].apply(get_coord, column='arrival', axis=1, result_type='expand')\n",
    "df.loc[null_coordinates & close_to_airport & landing, 'latitude'] = coordinates[0]\n",
    "df.loc[null_coordinates & close_to_airport & landing, 'longitude'] = coordinates[1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "df.to_csv('data/imputed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('data/imputed_data.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inpute missing other_fatalities to 0\n",
    "df['other_fatalities'] = df['other_fatalities'].fillna(0)\n",
    "assert df['other_fatalities'].isna().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_null_columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop redundant/unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**registration, msn**<br>\n",
    "Those are unique identifiers or an aircraft.\n",
    "\n",
    "**flight_number**<br>\n",
    "It's an unique identifier of an flight.\n",
    "\n",
    "**captain_flying_hours, captain_flying_hours_on_type, copilot_flying_hours, copilot_flying_hours_on_type, aircraft_flying_hours, aircraft_flight_cycles**<br>\n",
    "There are too many null values.\n",
    "\n",
    "**first_flight**<br>\n",
    "It's the first flight of the aircraft type in general, not the one involved in the accident\n",
    "\n",
    "**investigating_agency, confidence_rating**<br>\n",
    "It won't help categorize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "  'registration',\n",
    "  'msn',\n",
    "  'flight_number',\n",
    "  'captain_flying_hours', \n",
    "  'captain_flying_hours_on_type', \n",
    "  'copilot_flying_hours',\n",
    "  'copilot_flying_hours_on_type',\n",
    "  'aircraft_flying_hours', \n",
    "  'aircraft_flight_cycles',\n",
    "  'first_flight',\n",
    "  'investigating_agency',\n",
    "  'confidence_rating']\n",
    "\n",
    "df = df.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collapse categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values of flight_type\n",
    "df['flight_type'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regroup values\n",
    "df['flight_type'] = np.where(df['flight_type'] == '-', 'Unknown', df['flight_type'])\n",
    "df['flight_type'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values of aircraft_damage\n",
    "df['aircraft_damage'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regroup values\n",
    "df['aircraft_damage'] = df['aircraft_damage'].str.replace(', written off', '')\n",
    "df['aircraft_damage'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values of cause\n",
    "df['cause'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regroup categories\n",
    "df['category'] = np.where(df['category'] == 'UK', 'Unknown', df['category'])\n",
    "df['category'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert category, aircraft_damage and engine into ordinal categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['category'].sort_values().unique())\n",
    "categories = ['Unknown', 'Incident', 'Serious incident', 'Accident', 'Unlawful Interference']\n",
    "df['category'] = pd.Categorical(df['category'], categories, ordered=True)\n",
    "df['category'] = df['category'].fillna('Unknown')\n",
    "print(df['category'].sort_values().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['aircraft_damage'].sort_values().unique())\n",
    "categories = [\n",
    "  \t'Unknown',\n",
    "  \t'Minor, repaired',\n",
    "  \t'Minor',\n",
    "  \t'Substantial, repaired',\n",
    "  \t'Substantial',\n",
    "\t'Destroyed',\n",
    "  \t'Aircraft missing']\n",
    "df['aircraft_damage'] = pd.Categorical(df['aircraft_damage'], categories, ordered=True)\n",
    "print(df['aircraft_damage'].sort_values().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['engine'].unique())\n",
    "df['engine'] = np.where(df['engine'].isin([\n",
    "  '2 Piston engines',\n",
    "  '3 Piston engines',\n",
    "  '4 Piston engines',\n",
    "  '6 Piston engines']), 'Multi Piston Engines', df['engine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['engine'] = np.where(df['engine'].isin([\n",
    "  '2 Turboprop engines',\n",
    "  '3 Turboprop engines',\n",
    "  '4 Turboprop engines']), 'Multi Turboprop Engines', df['engine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['engine'] = np.where(df['engine'].isin([\n",
    "  '2 Jet engines',\n",
    "  '3 Jet engines',\n",
    "  '4 Jet engines']), 'Multi Jet Engines', df['engine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "  'Unknown',\n",
    "  '1 Piston engine',\n",
    "  'Multi Piston Engines',\n",
    "  '1 Turboprop engine',\n",
    "  'Multi Turboprop Engines',\n",
    "  '1 Jet engine',\n",
    "  'Multi Jet Engines']\n",
    "df['engine'] = pd.Categorical(df['engine'], categories, ordered=True)\n",
    "print(df['engine'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct other inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows with yom below 1900\n",
    "low_yom = df['yom'] < 1900\n",
    "df[low_yom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with average\n",
    "df.loc[low_yom, 'yom'] = df['date'].dt.year - int(df['aircraft_age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get row with 5 digit yom\n",
    "high_yom = df['yom'] > 2025\n",
    "df[high_yom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After checking in the BAAA and ASN website, replace with 1956\n",
    "df.loc[high_yom, 'yom'] = 1956"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert there are no more null values\n",
    "assert df.isna().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "df = df[[\n",
    "\t'date',\n",
    "  \t'category',\n",
    "\t'type',\n",
    "\t'operator',\n",
    "\t'yom',\n",
    "\t'engine',\n",
    "\t'engine_model',\n",
    "\t'flight_phase',\n",
    "\t'flight_type',\n",
    "\t'site',\n",
    "\t'location',\n",
    "\t'country',\n",
    "\t'region',\n",
    "\t'latitude',\n",
    "\t'longitude',\n",
    "\t'aircraft_damage',\n",
    "\t'occupants',\n",
    "\t'fatalities',\n",
    "\t'other_fatalities',\n",
    "\t'cause'\n",
    "  ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data from the earliest to the latest crash\n",
    "df = df.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize data with pickle\n",
    "with open('data/cleaned_data.pkl', 'wb') as handle:\n",
    "  pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to CSV\n",
    "df.to_csv('data/cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
